# ğŸŒ Production RAG Anime Recommender

AI-powered anime recommendation system built with **RAG (Retrieval-Augmented Generation)**, deployed on **Kubernetes**.

![Python](https://img.shields.io/badge/Python-3.11-blue)
![LangChain](https://img.shields.io/badge/LangChain-LCEL-green)
![Kubernetes](https://img.shields.io/badge/Kubernetes-Minikube-blue)
![Docker](https://img.shields.io/badge/Docker-Containerized-blue)

## ğŸ¯ What It Does

Enter your anime preferences (e.g., "dark fantasy with complex plot") and get personalized recommendations powered by semantic search and LLM reasoning.

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|------------|
| **Vector Database** | ChromaDB with HuggingFace embeddings |
| **LLM** | Groq API (Llama 3.1 8B) |
| **Orchestration** | LangChain (LCEL) |
| **Frontend** | Streamlit |
| **Containerization** | Docker |
| **Deployment** | Kubernetes (Minikube) |

## ğŸ“š Learning Outcomes

By building this project, you'll learn:

### RAG Architecture
- How to build a production RAG pipeline from scratch
- Vector embeddings and semantic search concepts
- Prompt engineering for grounded responses

### LangChain & LLM Integration
- Modern LangChain Expression Language (LCEL)
- Connecting retrievers with LLMs
- Managing API keys securely with environment variables

### Containerization & Kubernetes
- Writing production Dockerfiles
- Kubernetes Deployments, Services, and Secrets
- Resource limits and health probes
- Debugging OOMKilled and CrashLoopBackOff errors

### MLOps/LLMOps
- End-to-end ML pipeline (data â†’ embeddings â†’ inference)
- Environment management with `uv`
- Git workflow for ML projects

## ğŸš€ Quick Start

### Local Development
```bash
# Clone the repo
git clone https://github.com/PranavAthanimath/production-rag-anime-recommender.git
cd production-rag-anime-recommender

# Create virtual environment
uv venv --python 3.11
.venv\Scripts\activate  # Windows

# Install dependencies
uv pip install -r requirements.txt -e .

# Set up environment
echo "GROQ_API_KEY=your-key-here" > .env

# Run the app
streamlit run app/app.py
```

### Kubernetes Deployment
```bash
# Start Minikube
minikube start

# Use Minikube's Docker
eval $(minikube docker-env)

# Build image
docker build -t anime-recommender:v1.0 .

# Create secret
kubectl create secret generic anime-secrets \
  --from-literal=GROQ_API_KEY=your-key

# Deploy
kubectl apply -f llmops-k8s.yaml

# Access the app
kubectl port-forward svc/anime-recommender-service 8501:80 --address 0.0.0.0
```

## ğŸ“ Project Structure

```
â”œâ”€â”€ app/app.py              # Streamlit UI
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loader.py      # Data processing
â”‚   â”œâ”€â”€ vector_store.py     # ChromaDB builder
â”‚   â”œâ”€â”€ recommender.py      # RAG chain
â”‚   â””â”€â”€ prompt_template.py  # LLM prompts
â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ pipeline.py         # Main pipeline
â”‚   â””â”€â”€ build_pipeline.py   # Vector store builder
â”œâ”€â”€ chroma_db/              # Pre-built vector database
â”œâ”€â”€ Dockerfile              # Container config
â”œâ”€â”€ llmops-k8s.yaml         # Kubernetes deployment
â””â”€â”€ requirements.txt        # Dependencies
```

## ğŸ› Troubleshooting

| Issue | Solution |
|-------|----------|
| `OOMKilled` | Increase memory in `llmops-k8s.yaml` to 2Gi |
| `ImagePullBackOff` | Build image with `eval $(minikube docker-env)` first |
| `Connection error` | Wait 2-3 min for pipeline init, add CORS flags to Dockerfile |

## ğŸ“„ License

MIT License - feel free to use for learning!

---

Built by [Pranav Athanimath](https://github.com/PranavAthanimath)
